---
title: "Analyse des données avec Dada2"
author : Mélody Lebrun
date: "3 janvier 2022"
output: 
  github_document:
    toc: true
    toc_depth: 2
---

L'objectif de ce travail est de comparer les résultats des analyses des données de l'article basée sur la méthode d'analyse des séquences par OTU (Operational Taxonomic Units) (97% de similarité) à la méthode ASV (Amplicon Sequence Variants). 
Ainsi, les résultats obtenue par la méthode ASV devraient être plus précis et moins erronés que par OTU. En effet, la méthode ASV permet de détecter les erreurs de séquençage, possède une résolution plus élevé sur l'identification de l'espèce et permet de comparer plusieurs études entre eux.   

Les données choisi proviennent soit du contenu des intestins de 14 Abatus agassizii (oursin) ou des tissus intestinaux ou encore des sédiments à proximité des oursins échantillonnées. L'échantillonnage a été réalisé au niveau de 2 sites séparés par 2 km. Les échantillons ont été séquencé par illumina miseq. Le dossier data_1 contient l'ARNr16s de ces échantillons. 
Le but de dada2 est de préparer les données pour les prochaines analyses en identifiant les erreurs de séquençage. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Préparation de l'environnement

```{r}
library(Rcpp)
library(dada2)
```

```{r}
set.seed(100)
```

14 contenus intestinaux, 14 tissus intestinaux, 8 sédiments ARNr16S V4 et V5 
```{r}
miseq_path <- "./data_1"
list.files(miseq_path)
```

# Mettre en ordre les séquences
Lire le nom des fichiers et les mettre dans l'ordre
FnFs : Fichiers Fastq R1
FnRs : Fichiers Fastq R2 

```{r}
fnFs <- sort(list.files(miseq_path, pattern="_1.fastq"))
fnRs <- sort(list.files(miseq_path, pattern="_2.fastq"))
sampleNames <- sapply(strsplit(fnFs, "_"), `[`, 1)
fnFs <- file.path(miseq_path, fnFs)
fnRs <- file.path(miseq_path, fnRs)
fnFs[1:3]
```

```{r}
fnRs[1:3]
```

# Graphique pour inspecter les prodilfs de qualité des lectures 

```{r}
plotQualityProfile(fnFs[1:2])
```
Profils de qualité des read arrière du premier et du deuxième read de la variable FnRs par une carte thermique. La ligne verte correspond au score de qualité moyen. La qulités de ces reads sont beaucoup moins bonnes sur la fin, ce qui n'est pas étonnant étant donné que le séquençage a été réalisé par Illumina. 

# Rogner et Filtrer les lectures

Filtfs : reads FnFs filtrés
FiltRs : reads FnRs filtrés
```{r}
filt_path <- file.path(miseq_path, "filtered") 
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(filt_path, paste0(sampleNames, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sampleNames, "_R_filt.fastq.gz"))
```

Filtration et rognage selon les paramètres : 
```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, compress=TRUE, multithread=TRUE)
head(out)
```

# Déduire des variantes de séquences (ASV)  
Combiner les lectures de séquençage en une séquence unique

```{r message = FALSE}
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
names(derepFs) <- sampleNames
names(derepRs) <- sampleNames
```
# Connaître le taux d'erreur de séquençage 

Pour cela, DADA2 utilise un modèle d'erreur permettant de déterminer les positions possèdant les probabilités les plus fortes d'erreurs. 

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

Read avant :
100371600 base en totale en 418215 reads, 13 echantillons sont utilisés pour connaîtres les taux d'erreurs.


```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```

Read arrière :
101364320 bases totale en 633527 reads, 19 échantillons sont utilisés pour connaîtres les taux d'erreurs. 

```{r}
plotErrors(errF)
plotErrors(errR)
```

Graphique représentant la probabilité d'une mauvaise base en fonction du Qscore (probabilité que la base soit correcte)
x : probabilité 
y : Qscore

Les points représentent les taux d'erreurs observés pour chaque score de qualité du consensus. 
La ligne noire représente les taux d'erreurs estimés après convergence de l'algorithme d'apprentissage machine. 

On observe que le taux d'erreur estimé (lignes noires) et le taux d'erreur observé (points noires) sont similaires. (les deux courbes se superposent)

# Méthode d'Interférence de Dada2 pour enlevé les bruits de fond

```{r}
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
```
```{r}
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
```
```{r}
dadaFs[[1]]
```

# Construire une table d'unité écologique

D'abord les reads avant et arrières sont fusionnées pour former des contigs

```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)
```

Puis construire une table de ASV vairant de Séquence d'Amplicon
```{r}
seqtabAll <- makeSequenceTable(mergers[!grepl("Mock", names(mergers))])
table(nchar(getSequences(seqtabAll)))
```

Detection des chimères 

```{r}
seqtabNoC <- removeBimeraDenovo(seqtabAll, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtabNoC)
```

# Calculs du ratio séquence non chimérique et chimérique

```{r}
sum(seqtabNoC)/sum(seqtabAll)
```
On obtient 79,61 % de séquence non chimiérique donc des ASV qui ont former des contigs
```{r}
1-sum(seqtabNoC)/sum(seqtabAll)
```
20% de séquence chimère dans le jeu de données. Un taux qui me semble important. 

# Attribuer une taxonomie

```{bash message = FALSE}
cd ~
wget  https://zenodo.org/record/4587955/files/silva_nr99_v138.1_train_set.fa.gz
```

La taxonomie de silva est assigné à la table ASV. 

```{r}
taxTab<-assignTaxonomy(seqtabNoC, "~/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa.print<-taxTab
rownames(taxa.print) <- NULL
head(taxa.print)
```
# Sauvegarde de nos données ASV pour les prochaines analyses 
```{r}
save.image(file="02_Data-analysis-with-DADA2_FinalEnv")
```

